<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.24.0 by Michael Rose
  Copyright 2013-2020 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Publications - Society + AI &amp; Language Lab</title>
<meta name="description" content="At SAIL, we strive to advance Computational Social Science (CSS) by using AI and sociolinguistics to better understand how AI-mediated systems impact interactions across people and machines.">


  <meta name="author" content="Your Name">
  


<meta property="og:type" content="website">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Society + AI & Language Lab">
<meta property="og:title" content="Publications">
<meta property="og:url" content="https://lancewilhelm.github.io/SAIL-Lab/publications/">


  <meta property="og:description" content="At SAIL, we strive to advance Computational Social Science (CSS) by using AI and sociolinguistics to better understand how AI-mediated systems impact interactions across people and machines.">











  

  


<link rel="canonical" href="https://lancewilhelm.github.io/SAIL-Lab/publications/">




<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "Person",
      "name": "Society + AI & Language Lab",
      "url": "https://lancewilhelm.github.io/SAIL-Lab/"
    
  }
</script>







<!-- end _includes/seo.html -->



  <link href="/SAIL-Lab/feed.xml" type="application/atom+xml" rel="alternate" title="Society + AI & Language Lab Feed">


<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/SAIL-Lab/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css"></noscript>


  
    <link rel="stylesheet" href="/SAIL-Lab/assets/css/publications.css">
  





    <link rel="icon" href="/SAIL-Lab/favicon.ico" type="image/x-icon">
  </head>

  <body class="layout--single wide">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
          <a class="site-logo" href="/SAIL-Lab/"><img src="/SAIL-Lab/assets/images/sail_logo.png" alt="Society + AI & Language Lab"></a>
        
        <a class="site-title" href="/SAIL-Lab/">
          Society + AI & Language Lab
          
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/SAIL-Lab/projects/">Projects</a>
            </li><li class="masthead__menu-item">
              <a href="/SAIL-Lab/publications/">Publications</a>
            </li><li class="masthead__menu-item">
              <a href="/SAIL-Lab/lab-resources/">Lab Resources</a>
            </li><li class="masthead__menu-item">
              <a href="/SAIL-Lab/teaching/">Teaching</a>
            </li></ul>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      





<div id="main" role="main">
  


  <article class="page h-entry" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="Publications">
    
    
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title p-name" itemprop="headline">
            <a href="https://lancewilhelm.github.io/SAIL-Lab/publications/" class="u-url" itemprop="url">Publications
</a>
          </h1>
          


        </header>
      

      <section class="page__content e-content" itemprop="text">
        
        <div class="publications">
    <ol class="bibliography"><li><!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 preview"><figure>

  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/SAIL-Lab/assets/images/publication_preview/police.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="police.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>
</div>

        <!-- Entry bib key -->
        <div id="rho_EscalatedPoliceStops_2023" class="col-sm-8">
        <!-- Title -->
        <div class="title"><b>Escalated Police Stops of Black Men Are Linguistically and Psychologically Distinct in Their Earliest Moments</b></div>
        <!-- Author -->
        <div class="author">
        

        Eugenia H. Rho,&nbsp;Maggie Harrington,&nbsp;Yuyang Zhong,&nbsp;Reid Pryzant,&nbsp;Nicholas P. Camp,&nbsp;Dan Jurafsky,&nbsp;and&nbsp;Jennifer L. Eberhardt</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em></em>
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <!-- <a class="abstract btn btn-sm btn--primary z-depth-0" role="button">Abstract</a> -->
            <a href="https://www.pnas.org/doi/10.1073/pnas.2216162120" class="btn btn-sm btn--primary z-depth-0" role="button">Link</a>
            <a href="https://www.pnas.org/doi/epdf/10.1073/pnas.2216162120" class="btn btn-sm btn--primary z-depth-0" role="button">PDF <i class="fas fa-file-pdf"></i></a>
          </div>
          

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Across the United States, police chiefs, city officials, and community leaders alike have highlighted the need to de-escalate police encounters with the public. This concern about escalation extends from encounters involving use of force to routine car stops, where Black drivers are disproportionately pulled over. Yet, despite the calls for action, we know little about the trajectory of police stops or how escalation unfolds. In study 1, we use methods from computational linguistics to analyze police body-worn camera footage from 577 stops of Black drivers. We find that stops with escalated outcomes (those ending in arrest, handcuffing, or a search) diverge from stops without these outcomes in their earliest moments—even in the first 45 words spoken by the officer. In stops that result in escalation, officers are more likely to issue commands as their opening words to the driver and less likely to tell drivers the reason why they are being stopped. In study 2, we expose Black males to audio clips of the same stops and find differences in how escalated stops are perceived: Participants report more negative emotion, appraise officers more negatively, worry about force being used, and predict worse outcomes after hearing only the officer’s initial words in escalated versus non-escalated stops. Our findings show that car stops that end in escalated outcomes sometimes begin in an escalated fashion, with adverse effects for Black male drivers and, in turn, police–community relations.</p>
          </div>
        </div>
      </div></li>
<li><!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 preview"><figure>

  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/SAIL-Lab/assets/images/publication_preview/toxic.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="toxic.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>
</div>

        <!-- Entry bib key -->
        <div id="gunturi_ToxVisEnablingInterpretability_2023" class="col-sm-8">
        <!-- Title -->
        <div class="title"><b>ToxVis: Enabling Interpretability of Implicit vs. Explicit Toxicity Detection Models with Interactive Visualization</b></div>
        <!-- Author -->
        <div class="author">
        

        Uma Gunturi,&nbsp;Xiaohan Ding,&nbsp;and&nbsp;Eugenia H. Rho</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <!-- <a class="abstract btn btn-sm btn--primary z-depth-0" role="button">Abstract</a> -->
            <a href="http://arxiv.org/abs/2303.09402" class="btn btn-sm btn--primary z-depth-0" role="button">Link</a>
            <a href="http://arxiv.org/abs/2303.09402.pdf" class="btn btn-sm btn--primary z-depth-0" role="button">PDF <i class="fas fa-file-pdf"></i></a>
          </div>
          

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>The rise of hate speech on online platforms has led to an urgent need for effective content moderation. However, the subjective and multi-faceted nature of hateful online content, including implicit hate speech, poses significant challenges to human moderators and content moderation systems. To address this issue, we developed ToxVis, a visually interactive and explainable tool for classifying hate speech into three categories: implicit, explicit, and non-hateful. We fine-tuned two transformer-based models using RoBERTa, XLNET, and GPT-3 and used deep learning interpretation techniques to provide explanations for the classification results. ToxVis enables users to input potentially hateful text and receive a classification result along with a visual explanation of which words contributed most to the decision. By making the classification process explainable, ToxVis provides a valuable tool for understanding the nuances of hateful content and supporting more effective content moderation. Our research contributes to the growing body of work aimed at mitigating the harms caused by online hate speech and demonstrates the potential for combining state-of-the-art natural language processing models with interpretable deep learning techniques to address this critical issue. Finally, ToxVis can serve as a resource for content moderators, social media platforms, and researchers working to combat the spread of hate speech online.</p>
          </div>
        </div>
      </div></li>
<li><!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 preview"><figure>

  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/SAIL-Lab/assets/images/publication_preview/different.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="different.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>
</div>

        <!-- Entry bib key -->
        <div id="ding_SameWordsDifferent_2023" class="col-sm-8">
        <!-- Title -->
        <div class="title"><b>Same Words, Different Meanings: Semantic Polarization in Broadcast Media Language Forecasts Polarization on Social Media Discourse</b></div>
        <!-- Author -->
        <div class="author">
        

        Xiaohan Ding,&nbsp;Mike Horning,&nbsp;and&nbsp;Eugenia H. Rho</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <!-- <a class="abstract btn btn-sm btn--primary z-depth-0" role="button">Abstract</a> -->
            <a href="http://arxiv.org/abs/2301.08832" class="btn btn-sm btn--primary z-depth-0" role="button">Link</a>
            <a href="/SAIL-Lab/assets/pdf//home/lance/Documents/Lance%E2%80%99s%20Vault/attachments/articles/ding_SameWordsDifferent_2023.pdf;/home/lance/Zotero/storage/M3AWTFRF/2301.html" class="btn btn-sm btn--primary z-depth-0" role="button">PDF</a>
          </div>
          

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>With the growth of online news over the past decade, empirical studies on political discourse and news consumption have focused on the phenomenon of filter bubbles and echo chambers. Yet recently, scholars have revealed limited evidence around the impact of such phenomenon, leading some to argue that partisan segregation across news audiences cannot be fully explained by online news consumption alone and that the role of traditional legacy media may be as salient in polarizing public discourse around current events. In this work, we expand the scope of analysis to include both online and more traditional media by investigating the relationship between broadcast news media language and social media discourse. By analyzing a decade’s worth of closed captions (2 million speaker turns) from CNN and Fox News along with topically corresponding discourse from Twitter, we provide a novel framework for measuring semantic polarization between America’s two major broadcast networks to demonstrate how semantic polarization between these outlets has evolved (Study 1), peaked (Study 2) and influenced partisan discussions on Twitter (Study 3) across the last decade. Our results demonstrate a sharp increase in polarization in how topically important keywords are discussed between the two channels, especially after 2016, with overall highest peaks occurring in 2020. The two stations discuss identical topics in drastically distinct contexts in 2020, to the extent that there is barely any linguistic overlap in how identical keywords are contextually discussed. Further, we demonstrate at scale, how such partisan division in broadcast media language significantly shapes semantic polarity trends on Twitter (and vice-versa), empirically linking for the first time, how online discussions are influenced by televised media.</p>
          </div>
        </div>
      </div></li></ol>
</div>

        
      </section>

      <footer class="page__meta">
        
        


        

      </footer>

      

      
    </div>

    
  </article>

  
  
</div>

    </div>

    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    

    
      
        
      
        
      
        
      
        
      
        
      
        
      
    

    
      <li><a href="/SAIL-Lab/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2023 Society + AI & Language Lab. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/SAIL-Lab/assets/js/main.min.js"></script>










  </body>
</html>
