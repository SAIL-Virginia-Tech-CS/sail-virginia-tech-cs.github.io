<meta http-equiv="Content-Type" content="text/html; charset=utf-8"><link type="text/css" rel="stylesheet" href="resources/sheet.css" >
<style type="text/css">.ritz .waffle a { color: inherit; }.ritz .waffle .s4{border-bottom:1px SOLID #000000;border-right:1px SOLID #000000;background-color:#ffffff;text-align:center;color:#000000;font-family:'Arial';font-size:12pt;vertical-align:middle;white-space:normal;overflow:hidden;word-wrap:break-word;direction:ltr;padding:0px 3px 0px 3px;}.ritz .waffle .s33{border-bottom:1px SOLID #000000;border-right:1px SOLID #000000;background-color:#ffe598;text-align:center;font-weight:bold;color:#000000;font-family:'Arial';font-size:12pt;vertical-align:middle;white-space:normal;overflow:hidden;word-wrap:break-word;direction:ltr;padding:0px 3px 0px 3px;}.ritz .waffle .s22{border-bottom:1px SOLID #000000;border-right:1px SOLID #000000;background-color:#ffff00;text-align:center;font-weight:bold;color:#000000;font-family:'Arial';font-size:12pt;vertical-align:middle;white-space:normal;overflow:hidden;word-wrap:break-word;direction:ltr;padding:0px 3px 0px 3px;}.ritz .waffle .s7{background-color:#ffffff;text-align:center;color:#000000;font-family:'Arial';font-size:12pt;vertical-align:middle;white-space:nowrap;direction:ltr;padding:0px 3px 0px 3px;}.ritz .waffle .s18{border-bottom:1px SOLID #000000;border-right:1px SOLID #000000;background-color:#ffd965;text-align:center;font-weight:bold;color:#000000;font-family:'Arial';font-size:12pt;vertical-align:middle;white-space:normal;overflow:hidden;word-wrap:break-word;direction:ltr;padding:0px 3px 0px 3px;}.ritz .waffle .s5{border-bottom:1px SOLID #000000;border-right:1px SOLID #000000;background-color:#ffffff;text-align:left;text-decoration:underline;-webkit-text-decoration-skip:none;text-decoration-skip-ink:none;color:#0070c0;font-family:'Arial';font-size:12pt;vertical-align:middle;white-space:normal;overflow:hidden;word-wrap:break-word;direction:ltr;padding:0px 3px 0px 3px;}.ritz .waffle .s13{border-right:1px SOLID #000000;background-color:#ffffff;text-align:left;color:#000000;font-family:'Arial';font-size:12pt;vertical-align:middle;white-space:normal;overflow:hidden;word-wrap:break-word;direction:ltr;padding:0px 3px 0px 3px;}.ritz .waffle .s8{background-color:#ffffff;text-align:center;color:#000000;font-family:'docs-Calibri',Arial;font-size:12pt;vertical-align:middle;white-space:nowrap;direction:ltr;padding:0px 3px 0px 3px;}.ritz .waffle .s31{border-bottom:1px SOLID #000000;border-right:1px SOLID #000000;background-color:#ffff00;text-align:center;font-weight:bold;color:#ff0000;font-family:'Arial';font-size:12pt;vertical-align:middle;white-space:nowrap;direction:ltr;padding:0px 3px 0px 3px;}.ritz .waffle .s24{background-color:#ffffff;text-align:center;color:#0096ff;font-family:'Arial';font-size:12pt;vertical-align:middle;white-space:nowrap;direction:ltr;padding:0px 3px 0px 3px;}.ritz .waffle .s2{background-color:#ffffff;text-align:center;font-weight:bold;color:#000000;font-family:'docs-Calibri',Arial;font-size:12pt;vertical-align:middle;white-space:nowrap;direction:ltr;padding:0px 3px 0px 3px;}.ritz .waffle .s27{background-color:#ffffff;text-align:center;text-decoration:underline;-webkit-text-decoration-skip:none;text-decoration-skip-ink:none;color:#000000;font-family:'Arial';font-size:12pt;vertical-align:middle;white-space:nowrap;direction:ltr;padding:0px 3px 0px 3px;}.ritz .waffle .s12{border-bottom:1px SOLID #000000;border-right:1px SOLID #000000;background-color:#ffff00;text-align:center;font-weight:bold;color:#ff0000;font-family:'Arial';font-size:12pt;vertical-align:middle;white-space:normal;overflow:hidden;word-wrap:break-word;direction:ltr;padding:0px 3px 0px 3px;}.ritz .waffle .s32{border-bottom:1px SOLID #000000;background-color:#ffffff;text-align:left;font-weight:bold;color:#000000;font-family:'Arial';font-size:12pt;vertical-align:middle;white-space:nowrap;direction:ltr;padding:0px 3px 0px 3px;}.ritz .waffle .s29{background-color:#ffffff;text-align:center;text-decoration:underline;-webkit-text-decoration-skip:none;text-decoration-skip-ink:none;color:#000000;font-family:'docs-Calibri',Arial;font-size:12pt;vertical-align:middle;white-space:nowrap;direction:ltr;padding:0px 3px 0px 3px;}.ritz .waffle .s25{border-bottom:1px SOLID #000000;border-right:1px SOLID #000000;background-color:#ffffff;text-align:left;text-decoration:underline;-webkit-text-decoration-skip:none;text-decoration-skip-ink:none;color:#0096ff;font-family:'Arial';font-size:12pt;vertical-align:middle;white-space:normal;overflow:hidden;word-wrap:break-word;direction:ltr;padding:0px 3px 0px 3px;}.ritz .waffle .s10{border-bottom:1px SOLID #000000;border-right:1px SOLID #000000;background-color:#ffffff;text-align:left;text-decoration:underline;-webkit-text-decoration-skip:none;text-decoration-skip-ink:none;color:#0563c1;font-family:'Arial';font-size:12pt;vertical-align:middle;white-space:normal;overflow:hidden;word-wrap:break-word;direction:ltr;padding:0px 3px 0px 3px;}.ritz .waffle .s17{border-bottom:1px SOLID #000000;background-color:#b6d7a8;text-align:center;color:#000000;font-family:'Arial';font-size:12pt;vertical-align:middle;white-space:nowrap;direction:ltr;padding:0px 3px 0px 3px;}.ritz .waffle .s19{border-bottom:1px SOLID #000000;background-color:#ffffff;text-align:left;font-weight:bold;color:#000000;font-family:'Arial';font-size:12pt;vertical-align:middle;white-space:normal;overflow:hidden;word-wrap:break-word;direction:ltr;padding:0px 3px 0px 3px;}.ritz .waffle .s11{border-bottom:1px SOLID #000000;border-right:1px SOLID #000000;background-color:#ffffff;text-align:left;text-decoration:underline;-webkit-text-decoration-skip:none;text-decoration-skip-ink:none;color:#0070c0;font-family:'Arial';font-size:12pt;vertical-align:top;white-space:normal;overflow:hidden;word-wrap:break-word;direction:ltr;padding:0px 3px 0px 3px;}.ritz .waffle .s26{border-bottom:1px SOLID #000000;background-color:#ffffff;text-align:center;text-decoration:underline;-webkit-text-decoration-skip:none;text-decoration-skip-ink:none;color:#000000;font-family:'Arial';font-size:12pt;vertical-align:middle;white-space:nowrap;direction:ltr;padding:0px 3px 0px 3px;}.ritz .waffle .s14{border-bottom:1px SOLID #000000;border-right:1px SOLID #000000;background-color:#ffffff;text-align:left;color:#000000;font-family:'Arial';font-size:12pt;vertical-align:middle;white-space:normal;overflow:hidden;word-wrap:break-word;direction:ltr;padding:0px 3px 0px 3px;}.ritz .waffle .s28{background-color:#ffffff;text-align:center;text-decoration:underline;-webkit-text-decoration-skip:none;text-decoration-skip-ink:none;color:#0096ff;font-family:'Arial';font-size:12pt;vertical-align:middle;white-space:nowrap;direction:ltr;padding:0px 3px 0px 3px;}.ritz .waffle .s30{background-color:#ffffff;text-align:center;color:#0563c1;font-family:'Arial';font-size:12pt;vertical-align:middle;white-space:nowrap;direction:ltr;padding:0px 3px 0px 3px;}.ritz .waffle .s9{background-color:#ffffff;text-align:left;color:#000000;font-family:'docs-Calibri',Arial;font-size:12pt;vertical-align:middle;white-space:nowrap;direction:ltr;padding:0px 3px 0px 3px;}.ritz .waffle .s6{border-bottom:1px SOLID #000000;background-color:#ffffff;text-align:center;color:#000000;font-family:'Arial';font-size:12pt;vertical-align:middle;white-space:nowrap;direction:ltr;padding:0px 3px 0px 3px;}.ritz .waffle .s23{border-right:1px SOLID #000000;background-color:#ffffff;text-align:center;color:#000000;font-family:'Arial';font-size:12pt;vertical-align:middle;white-space:normal;overflow:hidden;word-wrap:break-word;direction:ltr;padding:0px 3px 0px 3px;}.ritz .waffle .s16{border-bottom:1px SOLID #000000;background-color:#ffffff;text-align:center;color:#000000;font-family:'Arial';font-size:12pt;vertical-align:middle;white-space:normal;overflow:hidden;word-wrap:break-word;direction:ltr;padding:0px 3px 0px 3px;}.ritz .waffle .s15{border-bottom:1px SOLID #000000;border-right:1px SOLID #000000;background-color:#fbe4d5;text-align:center;font-weight:bold;font-style:italic;color:#000000;font-family:'Arial';font-size:12pt;vertical-align:middle;white-space:nowrap;direction:ltr;padding:0px 3px 0px 3px;}.ritz .waffle .s0{border-bottom:1px SOLID #000000;border-right:1px SOLID #000000;background-color:#ffffff;text-align:center;font-weight:bold;color:#000000;font-family:'Arial';font-size:12pt;vertical-align:middle;white-space:normal;overflow:hidden;word-wrap:break-word;direction:ltr;padding:0px 3px 0px 3px;}.ritz .waffle .s3{background-color:#ffffff;text-align:left;color:#000000;font-family:'docs-Calibri',Arial;font-size:12pt;vertical-align:bottom;white-space:nowrap;direction:ltr;padding:0px 3px 0px 3px;}.ritz .waffle .s1{background-color:#ffffff;text-align:left;color:#ffffff;font-family:'Arial';font-size:12pt;vertical-align:middle;white-space:nowrap;direction:ltr;padding:0px 3px 0px 3px;}.ritz .waffle .s21{background-color:#ffffff;text-align:left;font-weight:bold;color:#000000;font-family:'docs-Calibri',Arial;font-size:12pt;vertical-align:bottom;white-space:nowrap;direction:ltr;padding:0px 3px 0px 3px;}.ritz .waffle .s20{background-color:#ffffff;text-align:center;font-weight:bold;color:#000000;font-family:'Arial';font-size:12pt;vertical-align:middle;white-space:nowrap;direction:ltr;padding:0px 3px 0px 3px;}</style><div class="ritz grid-container" dir="ltr"><table class="waffle" cellspacing="0" cellpadding="0"><thead><tr><th class="row-header freezebar-origin-ltr"></th><th id="380029853C0" style="width:140px;" class="column-headers-background">A</th><th id="380029853C1" style="width:209px;" class="column-headers-background">B</th><th id="380029853C2" style="width:621px;" class="column-headers-background">C</th><th id="380029853C3" style="width:193px;" class="column-headers-background">D</th><th id="380029853C4" style="width:600px;" class="column-headers-background">E</th><th id="380029853C5" style="width:600px;" class="column-headers-background">F</th><th id="380029853C6" style="width:600px;" class="column-headers-background">G</th><th id="380029853C7" style="width:93px;" class="column-headers-background">H</th><th id="380029853C8" style="width:93px;" class="column-headers-background">I</th><th id="380029853C9" style="width:93px;" class="column-headers-background">J</th><th id="380029853C10" style="width:93px;" class="column-headers-background">K</th><th id="380029853C11" style="width:93px;" class="column-headers-background">L</th><th id="380029853C12" style="width:93px;" class="column-headers-background">M</th><th id="380029853C13" style="width:93px;" class="column-headers-background">N</th><th id="380029853C14" style="width:93px;" class="column-headers-background">O</th><th id="380029853C15" style="width:93px;" class="column-headers-background">P</th><th id="380029853C16" style="width:93px;" class="column-headers-background">Q</th><th id="380029853C17" style="width:93px;" class="column-headers-background">R</th><th id="380029853C18" style="width:93px;" class="column-headers-background">S</th><th id="380029853C19" style="width:93px;" class="column-headers-background">T</th><th id="380029853C20" style="width:93px;" class="column-headers-background">U</th><th id="380029853C21" style="width:93px;" class="column-headers-background">V</th><th id="380029853C22" style="width:93px;" class="column-headers-background">W</th><th id="380029853C23" style="width:99px;" class="column-headers-background">X</th><th id="380029853C24" style="width:99px;" class="column-headers-background">Y</th></tr></thead><tbody><tr style="height: 30px"><th id="380029853R0" style="height: 30px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 30px">1</div></th><td class="s0">Date</td><td class="s0">Topic</td><td class="s0">Reading</td><td class="s0" dir="ltr">Presenter</td><td class="s1"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s3"></td><td class="s3"></td></tr><tr style="height: 19px"><th id="380029853R1" style="height: 19px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 19px">2</div></th><td class="s4" rowspan="2">21-Aug</td><td class="s4" rowspan="2">Introduction and Course Overview</td><td class="s5"><a target="_blank" href="https://groups.csail.mit.edu/medg/people/psz/Licklider.html">Licklider, Joseph CR. &quot;Man-computer symbiosis.&quot; IRE transactions on human factors in electronics 1 (1960): 4-11. (read in class) </a></td><td class="s6" rowspan="10">DO NOT SIGN UP</td><td class="s7"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s9"></td><td class="s9"></td></tr><tr style="height: 19px"><th id="380029853R2" style="height: 19px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 19px">3</div></th><td class="s5"><a target="_blank" href="https://www.ted.com/talks/shyam_sankar_the_rise_of_human_computer_cooperation">Shyam Sankar. The Rise of Human Computer Cooperation. TED Talk Video, 2012 (12 mins).</a></td><td class="s7"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s9"></td><td class="s9"></td></tr><tr style="height: 19px"><th id="380029853R3" style="height: 19px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 19px">4</div></th><td class="s4" rowspan="3">23-Aug</td><td class="s4" rowspan="3">Primer on AI</td><td class="s5"><a target="_blank" href="http://papers.nips.cc/paper/8301-ask-not-what-ai-can-do-but-what-ai-should-do-towards-a-framework-of-task-delegability">Lubars, Brian, and Chenhao Tan. &quot;Ask not what AI can do, but what AI should do: Towards a framework of task delegability.&quot; In Advances in Neural Information Processing Systems, pp. 57-67. 2019.</a></td><td class="s7"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s9"></td><td class="s9"></td></tr><tr style="height: 19px"><th id="380029853R4" style="height: 19px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 19px">5</div></th><td class="s5"><a target="_blank" href="http://library.usc.edu.ph/ACM/CHI%202017/1proc/p3506.pdf">Xu, Anbang, Zhe Liu, Yufan Guo, Vibha Sinha, and Rama Akkiraju. &quot;A new chatbot for customer service on social media.&quot; In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems, pp. 3506-3510. 2017.</a></td><td class="s7"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s9"></td><td class="s9"></td></tr><tr style="height: 19px"><th id="380029853R5" style="height: 19px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 19px">6</div></th><td class="s5"><a target="_blank" href="https://towardsdatascience.com/getting-started-with-reading-deep-learning-research-papers-the-why-and-the-how-dfd1ac15dbc0">Nityesh Agarwal. &quot;Getting started with reading Deep Learning Research papers: The Why and the How&quot;, a blog post at Towards Data Science (2018).</a></td><td class="s7"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s9"></td><td class="s9"></td></tr><tr style="height: 19px"><th id="380029853R6" style="height: 19px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 19px">7</div></th><td class="s4" rowspan="2">28-Aug</td><td class="s4" rowspan="2">LLM Overview</td><td class="s10" dir="ltr"><a target="_blank" href="https://arxiv.org/abs/2212.03551">Shanahan, M. (2022). Talking about large language models. arXiv preprint arXiv:2212.03551.<br> Optional:  Zhao, W. X., Zhou, K., Li, J., Tang, T., Wang, X., Hou, Y., ... &amp; Wen, J. R. (2023). A survey of large language models. arXiv preprint arXiv:2303.18223.</a></td><td class="s7"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s9"></td><td class="s9"></td></tr><tr style="height: 19px"><th id="380029853R7" style="height: 19px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 19px">8</div></th><td class="s11" dir="ltr"><a target="_blank" href="https://www.newyorker.com/tech/annals-of-technology/can-computers-learn-common-sense">1. Can Computers Learn Common Sense?, The New Yorker, 2022 (optional)The Race to Make A.I. Smaller (and Smarter)<br>2. A mental health tech company ran an AI experiment on real users. Nothing’s stopping apps from conducting more.</a></td><td class="s7"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s9"></td><td class="s9"></td></tr><tr style="height: 19px"><th id="380029853R8" style="height: 19px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 19px">9</div></th><td class="s4" rowspan="3">30-Aug</td><td class="s4" rowspan="3">Primer on HCI</td><td class="s5"><a target="_blank" href="https://dl.acm.org/doi/abs/10.1145/3290605.3300233"> Amershi, Saleema, et al. &quot;Guidelines for human-AI interaction.&quot; Proceedings of the 2019 chi conference on human factors in computing systems. 2019.</a></td><td class="s7"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s9"></td><td class="s9"></td></tr><tr style="height: 19px"><th id="380029853R9" style="height: 19px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 19px">10</div></th><td class="s10"><a target="_blank" href="https://dl.acm.org/doi/10.1145/3313831.3376301">Yang et al., Re-examining Whether, Why, and How Human-AI Interaction Is Uniquely Difficult to Design (CHI 2020)</a></td><td class="s7"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s9"></td><td class="s9"></td></tr><tr style="height: 19px"><th id="380029853R10" style="height: 19px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 19px">11</div></th><td class="s5"><a target="_blank" href="https://arxiv.org/abs/2002.04087">Shneiderman, B., &quot;Human-Centered Artificial Intelligence: Reliable, Safe &amp; Trustworthy.&quot; International Journal of Human-Computer Interaction 36, 6, 495-504. 2020.</a></td><td class="s7"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s9"></td><td class="s9"></td></tr><tr style="height: 19px"><th id="380029853R11" style="height: 19px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 19px">12</div></th><td class="s12" rowspan="2">4-Sep</td><td class="s12" colspan="2" rowspan="2">Labor Day No Classes</td><td class="s13"></td><td class="s7"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s3"></td><td class="s3"></td></tr><tr style="height: 19px"><th id="380029853R12" style="height: 19px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 19px">13</div></th><td class="s14"></td><td class="s7"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s3"></td><td class="s3"></td></tr><tr style="height: 19px"><th id="380029853R13" style="height: 19px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 19px">14</div></th><td class="s4">6-Sep</td><td class="s15" colspan="2">LLM Tutorial - 1 (come to class with laptop)</td><td class="s16"></td><td class="s7"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s3"></td><td class="s3"></td></tr><tr style="height: 19px"><th id="380029853R14" style="height: 19px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 19px">15</div></th><td class="s4" rowspan="3">11-Sep</td><td class="s4" rowspan="3">Prompting - 1</td><td class="s10"><a target="_blank" href="https://dl.acm.org/doi/10.1145/3544548.3581388">Zamfirescu-Pereira, J. D., Wong, R. Y., Hartmann, B., &amp; Yang, Q. (2023, April). Why Johnny can’t prompt: how non-AI experts try (and fail) to design LLM prompts. In Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems (pp. 1-21).</a></td><td class="s17">Zihao Lin + Sophia Stil</td><td class="s7"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s3"></td><td class="s3"></td></tr><tr style="height: 19px"><th id="380029853R15" style="height: 19px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 19px">16</div></th><td class="s5"><a target="_blank" href="https://dl.acm.org/doi/abs/10.1145/3491102.3517582">AI Chains: Transparent and Controllable Human-AI Interaction by Chaining Large Language Model Prompts, Tongshuang Wu, Michael Terry, Carrie J Cai - CHI 2022</a></td><td class="s6">Lance Wilhelm</td><td class="s7"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s3"></td><td class="s3"></td></tr><tr style="height: 19px"><th id="380029853R16" style="height: 19px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 19px">17</div></th><td class="s10"><a target="_blank" href="https://arxiv.org/abs/2107.13586">Skim: Liu, P., Yuan, W., Fu, J., Jiang, Z., Hayashi, H., &amp; Neubig, G. (2023). Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing. ACM Computing Surveys, 55(9), 1-35.</a></td><td class="s6">Hossein Naderi</td><td class="s7"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s3"></td><td class="s3"></td></tr><tr style="height: 19px"><th id="380029853R17" style="height: 19px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 19px">18</div></th><td class="s4" rowspan="2">13-Sep</td><td class="s4" rowspan="2">Prompting - 2</td><td class="s5"><a target="_blank" href="https://dl.acm.org/doi/10.1145/3491101.3519729">PromptChainer: Chaining Large Language Model Prompts through Visual Programming, Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, Carrie J Cai - CHI 2022</a></td><td class="s6">Kaike Ping</td><td class="s7"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s3"></td><td class="s3"></td></tr><tr style="height: 19px"><th id="380029853R18" style="height: 19px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 19px">19</div></th><td class="s5"><a target="_blank" href="https://arxiv.org/abs/2201.11903">Wei, Jason, et al. &quot;Chain-of-thought prompting elicits reasoning in large language models.&quot; Advances in Neural Information Processing Systems 35 (2022): 24824-24837.</a></td><td class="s17">Yeana Bond</td><td class="s7"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s3"></td><td class="s3"></td></tr><tr style="height: 19px"><th id="380029853R19" style="height: 19px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 19px">20</div></th><td class="s4">18-Sep</td><td class="s15" colspan="2">LLM Tutorial - 2 (come to class with laptop)</td><td class="s6"></td><td class="s7"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s3"></td><td class="s3"></td></tr><tr style="height: 19px"><th id="380029853R20" style="height: 19px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 19px">21</div></th><td class="s4" rowspan="3">20-Sep</td><td class="s4" rowspan="3">Fairness, Accountability, Transparency &amp; Ethics in LLMs - 1</td><td class="s5"><a target="_blank" href="https://arxiv.org/abs/1910.04210">Prabhakaran, Vinodkumar, Ben Hutchinson, and Margaret Mitchell. &quot;Perturbation sensitivity analysis to detect unintended model biases.&quot; arXiv preprint arXiv:1910.04210 (2019).</a></td><td class="s6">Haritha Gnanasegar</td><td class="s7"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s3"></td><td class="s3"></td></tr><tr style="height: 19px"><th id="380029853R21" style="height: 19px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 19px">22</div></th><td class="s5"><a target="_blank" href="https://arxiv.org/abs/2205.00501">Goyal, Nitesh, et al. &quot;Is Your Toxicity My Toxicity? Exploring the Impact of Rater Identity on Toxicity Annotation.&quot; Proceedings of the ACM on Human-Computer Interaction 6.CSCW2 (2022): 1-28.</a></td><td class="s6">Srujan Vithalani</td><td class="s7"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s3"></td><td class="s3"></td></tr><tr style="height: 19px"><th id="380029853R22" style="height: 19px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 19px">23</div></th><td class="s5"><a target="_blank" href="https://arxiv.org/abs/2107.00061">Clark, Elizabeth, et al. &quot;All that&#39;s&#39; human&#39;is not gold: Evaluating human evaluation of generated text.&quot; arXiv preprint arXiv:2107.00061 (2021).</a></td><td class="s6">Daniel Palamarchuk</td><td class="s7"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s3"></td><td class="s3"></td></tr><tr style="height: 19px"><th id="380029853R23" style="height: 19px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 19px">24</div></th><td class="s4" rowspan="2">25-Sep</td><td class="s4" rowspan="2">Fairness, Accountability, Transparency &amp; Ethics in LLMs - 2</td><td class="s10"><a target="_blank" href="https://dl.acm.org/doi/10.1145/3544548.3581196">Jakesch, M., Bhat, A., Buschek, D., Zalmanson, L., &amp; Naaman, M. (2023, April). Co-writing with opinionated language models affects users’ views. In Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems (pp. 1-15).</a></td><td class="s6">Steven DeVerteuil</td><td class="s7"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s3"></td><td class="s3"></td></tr><tr style="height: 19px"><th id="380029853R24" style="height: 19px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 19px">25</div></th><td class="s10"><a target="_blank" href="https://dl.acm.org/doi/10.1145/3544548.3581357">Wenzel, K., Devireddy, N., Davison, C., &amp; Kaufman, G. (2023, April). Can Voice Assistants Be Microaggressors? Cross-Race Psychological Responses to Failures of Automatic Speech Recognition. In Proceedings of the 2023 CHI Conference on Human Factors in Com</a></td><td class="s6">Lemara Williams</td><td class="s7"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s3"></td><td class="s3"></td></tr><tr style="height: 19px"><th id="380029853R25" style="height: 19px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 19px">26</div></th><td class="s4" rowspan="2">27-Sep</td><td class="s4" rowspan="2">Fairness, Accountability, Transparency &amp; Ethics in LLMs - 3</td><td class="s10"><a target="_blank" href="https://dl.acm.org/doi/10.1145/3491102.3517533">“Because AI is 100% right and safe”: User Vulnerabilities and Sources of AI Authority in India, Shivani Kapania, Oliver Siy, Gabe Clapper, Azhagu SP, Nithya Sambasivan - CHI 2022</a></td><td class="s6"></td><td class="s7"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s3"></td><td class="s3"></td></tr><tr style="height: 19px"><th id="380029853R26" style="height: 19px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 19px">27</div></th><td class="s10"><a target="_blank" href="https://arxiv.org/abs/2305.17174">Mendelsohn, J., Bras, R. L., Choi, Y., &amp; Sap, M. (2023). From Dogwhistles to Bullhorns: Unveiling Coded Rhetoric with Language Models. arXiv preprint arXiv:2305.17174.</a></td><td class="s6">Balu </td><td class="s7"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s3"></td><td class="s3"></td></tr><tr style="height: 37px"><th id="380029853R27" style="height: 37px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 37px">28</div></th><td class="s4">2-Oct</td><td class="s18" colspan="2">Project Pitch Presentations</td><td class="s6"></td><td class="s7"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s3"></td><td class="s3"></td></tr><tr style="height: 37px"><th id="380029853R28" style="height: 37px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 37px">29</div></th><td class="s4">4-Oct</td><td class="s18" colspan="2">Project Pitch Presentations</td><td class="s6"></td><td class="s7"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s3"></td><td class="s3"></td></tr><tr style="height: 37px"><th id="380029853R29" style="height: 37px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 37px">30</div></th><td class="s12">9-Oct</td><td class="s12" colspan="2">Columbus Day</td><td class="s19"></td><td class="s20"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s21"></td><td class="s21"></td></tr><tr style="height: 19px"><th id="380029853R30" style="height: 19px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 19px">31</div></th><td class="s4" rowspan="2">11-Oct</td><td class="s4" rowspan="2">LLM-Supported Health Care</td><td class="s10"><a target="_blank" href="https://dl.acm.org/doi/10.1145/3544548.3581503">Jo, E., Epstein, D. A., Jung, H., &amp; Kim, Y. H. (2023, April). Understanding the benefits and challenges of deploying conversational AI leveraging large language models for public health intervention. (CHI 2023)</a></td><td class="s16">Xiaozheng</td><td class="s20"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s21"></td><td class="s21"></td></tr><tr style="height: 19px"><th id="380029853R31" style="height: 19px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 19px">32</div></th><td class="s10"><a target="_blank" href="https://arxiv.org/abs/2305.13614">Chen, S., Wu, M., Zhu, K. Q., Lan, K., Zhang, Z., &amp; Cui, L. (2023). LLM-empowered Chatbots for Psychiatrist and Patient Simulation: Application and Evaluation. arXiv preprint arXiv:2305.13614.</a></td><td class="s16">Ashish</td><td class="s20"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s21"></td><td class="s21"></td></tr><tr style="height: 34px"><th id="380029853R32" style="height: 34px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 34px">33</div></th><td class="s4">October 16 - 18</td><td class="s22" colspan="2">Instuctor is out of town for CSCW</td><td class="s19"></td><td class="s20"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s2"></td><td class="s21"></td><td class="s21"></td></tr><tr style="height: 34px"><th id="380029853R33" style="height: 34px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 34px">34</div></th><td class="s4">23-Oct</td><td class="s15" colspan="2">Tutorial: Web Application Hosting for LLM-Powered Tools (come to class with laptop)</td><td class="s6"></td><td class="s7"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s3"></td><td class="s3"></td></tr><tr style="height: 19px"><th id="380029853R34" style="height: 19px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 19px">35</div></th><td class="s4" rowspan="3">25-Oct</td><td class="s4" rowspan="3">LLM Accesibility and Neurodiversity</td><td class="s10"><a target="_blank" href="https://dl.acm.org/doi/10.1145/3544548.3581560">Valencia, S., Cave, R., Kallarackal, K., Seaver, K., Terry, M., &amp; Kane, S. K. (2023, April). “The less I type, the better”: How AI Language Models can Enhance or Impede Communication for AAC Users. In Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems (pp. 1-14).</a></td><td class="s6">Andrew Fang</td><td class="s7"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s3"></td><td class="s3"></td></tr><tr style="height: 19px"><th id="380029853R35" style="height: 19px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 19px">36</div></th><td class="s10"><a target="_blank" href="https://www.wired.com/story/for-some-autistic-people-chatgpt-is-a-lifeline/#:~:text=Maxfield%20Sparrow%2C%20who%20is%20autistic,for%20neurotypical%20people%2C%20Sparrow%20says.">For Some Autistic People, ChatGPT Is a Lifeline, WIRED, 2023</a></td><td class="s6" rowspan="2">Stanley Gabriel + Malik </td><td class="s7"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s3"></td><td class="s3"></td></tr><tr style="height: 19px"><th id="380029853R36" style="height: 19px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 19px">37</div></th><td class="s10" dir="ltr"><a target="_blank" href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=10217349">Elshentenawy, M., Ahmed, M., Elalfy, M., Bakr, A., Heidar, M., &amp; Amer, E. (2023, July). Intellibot: A Personalized Behavioral Analysis Chatbot Framework Powered by GPT-3. In 2023 Intelligent Methods, Systems, and Applications (IMSA) (pp. 136-141). IEEE.</a></td><td class="s7"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s3"></td><td class="s3"></td></tr><tr style="height: 19px"><th id="380029853R37" style="height: 19px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 19px">38</div></th><td class="s23" rowspan="2">30-Oct</td><td class="s4" rowspan="2">LLM-Supported Work: Writing</td><td class="s10"><a target="_blank" href="https://dl.acm.org/doi/abs/10.1145/3491102.3502030">CoAuthor: Designing a Human-AI Collaborative Writing Dataset for Exploring Language Model Capabilities Mina Lee, Percy Liang, Qian Yang CHI 2022</a></td><td class="s6">Siddharth Chintamaneni</td><td class="s7"></td><td class="s24"></td><td class="s7"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s3"></td><td class="s3"></td></tr><tr style="height: 19px"><th id="380029853R38" style="height: 19px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 19px">39</div></th><td class="s10"><a target="_blank" href="https://johnr0.github.io/assets/publications/CHI2022-TaleBrush.pdf">Tale Brush: Sketching Stories with Generative Pretrained Language Models, John Joon Young Chung, Wooseok Kim, Kang Min Yoo, Hwaran Lee, Eytan Adar, Minsuk Chang CHI2022</a></td><td class="s6">Taufiq Daryanto</td><td class="s7"></td><td class="s24"></td><td class="s7"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s3"></td><td class="s3"></td></tr><tr style="height: 19px"><th id="380029853R39" style="height: 19px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 19px">40</div></th><td class="s4" rowspan="2">1-Nov</td><td class="s4" rowspan="2">LLM-Supported Work: Research</td><td class="s10"><a target="_blank" href="https://dl.acm.org/doi/10.1145/3544548.3580688">Hämäläinen, P., Tavast, M., &amp; Kunnari, A. (2023, April). Evaluating large language models in generating synthetic hci research data: a case study. In Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems (pp. 1-19).</a></td><td class="s6">Nicholas Kong</td><td class="s7"></td><td class="s24"></td><td class="s7"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s3"></td><td class="s3"></td></tr><tr style="height: 19px"><th id="380029853R40" style="height: 19px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 19px">41</div></th><td class="s25"><a target="_blank" href="https://dl.acm.org/doi/abs/10.1145/3526113.3545616">Park, Joon Sung, et al. &quot;Social Simulacra: Creating Populated Prototypes for Social Computing Systems.&quot; Proceedings of the 35th Annual ACM Symposium on User Interface Software and Technology. 2022.</a></td><td class="s6">Kaiyi Chen</td><td class="s7"></td><td class="s24"></td><td class="s7"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s3"></td><td class="s3"></td></tr><tr style="height: 36px"><th id="380029853R41" style="height: 36px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 36px">42</div></th><td class="s4">6-Nov</td><td class="s18" colspan="2">Prototype + Midterm Presentation</td><td class="s26"></td><td class="s27"></td><td class="s28"></td><td class="s27"></td><td class="s29"></td><td class="s29"></td><td class="s29"></td><td class="s29"></td><td class="s29"></td><td class="s29"></td><td class="s29"></td><td class="s29"></td><td class="s29"></td><td class="s29"></td><td class="s29"></td><td class="s29"></td><td class="s29"></td><td class="s29"></td><td class="s29"></td><td class="s29"></td><td class="s3"></td><td class="s3"></td></tr><tr style="height: 36px"><th id="380029853R42" style="height: 36px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 36px">43</div></th><td class="s4">8-Nov</td><td class="s18" colspan="2">Prototype + Midterm Presentation</td><td class="s6"></td><td class="s7"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s3"></td><td class="s3"></td></tr><tr style="height: 19px"><th id="380029853R43" style="height: 19px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 19px">44</div></th><td class="s4" rowspan="2">13-Nov</td><td class="s4" rowspan="2">Multimodality </td><td class="s5"><a target="_blank" href="https://arxiv.org/abs/2307.09474">Zhao, L., Yu, E., Ge, Z., Yang, J., Wei, H., Zhou, H., ... &amp; Zhang, X. (2023). ChatSpot: Bootstrapping Multimodal LLMs via Precise Referring Instruction Tuning. arXiv preprint arXiv:2307.09474. (Demo: https://chatspot.streamlit.app/)</a></td><td class="s6">Nikhil Narra</td><td class="s30"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s3"></td><td class="s3"></td></tr><tr style="height: 19px"><th id="380029853R44" style="height: 19px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 19px">45</div></th><td class="s5"><a target="_blank" href="https://arxiv.org/pdf/2304.09842.pdf">Chameleon: Plug-and-Play Compositional Reasoning with Large Language Models (demo: https://www.youtube.com/watch?v=EWFixIk4vjs&amp;t=2s)</a></td><td class="s6">Luis Lazcano</td><td class="s30"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s3"></td><td class="s3"></td></tr><tr style="height: 19px"><th id="380029853R45" style="height: 19px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 19px">46</div></th><td class="s4" rowspan="2">15-Nov</td><td class="s4" rowspan="2">Text to Visual/ Audio</td><td class="s10"><a target="_blank" href="https://arxiv.org/abs/2306.09093">Lyu, C., Wu, M., Wang, L., Huang, X., Liu, B., Du, Z., ... &amp; Tu, Z. (2023). Macaw-LLM: Multi-Modal Language Modeling with Image, Audio, Video, and Text Integration. arXiv preprint arXiv:2306.09093.</a></td><td class="s6">Ragul S</td><td class="s7"></td><td class="s8"></td><td class="s7"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s3"></td><td class="s3"></td></tr><tr style="height: 19px"><th id="380029853R46" style="height: 19px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 19px">47</div></th><td class="s5"><a target="_blank" href="https://arxiv.org/pdf/2301.12661.pdf">Make-An-Audio: Text-To-Audio Generation with Prompt-Enhanced Diffusion Models; Demo: HuggingFace Suno Bark Application or Demo of Choice</a></td><td class="s6">Premith Kumar Chilukuri</td><td class="s7"></td><td class="s8"></td><td class="s7"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s3"></td><td class="s3"></td></tr><tr style="height: 35px"><th id="380029853R47" style="height: 35px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 35px">48</div></th><td class="s31">November 19 - 23</td><td class="s31" colspan="2">Thanksgiving Break</td><td class="s32"></td><td class="s7"></td><td class="s8"></td><td class="s7"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s3"></td><td class="s3"></td></tr><tr style="height: 19px"><th id="380029853R48" style="height: 19px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 19px">49</div></th><td class="s4" rowspan="2">27-Nov</td><td class="s4" rowspan="2">Creative Applications</td><td class="s5"><a target="_blank" href="https://arxiv.org/abs/2303.07316">FaceChat: An Emotion-Aware Face-to-face Dialogue Framework</a></td><td class="s6">Tong Zeng</td><td class="s7" rowspan="2"></td><td class="s8"></td><td class="s8" rowspan="2"></td><td class="s8"></td><td class="s8" rowspan="2"></td><td class="s8"></td><td class="s8" rowspan="2"></td><td class="s8"></td><td class="s8" rowspan="2"></td><td class="s8"></td><td class="s8" rowspan="2"></td><td class="s8"></td><td class="s8" rowspan="2"></td><td class="s8"></td><td class="s8" rowspan="2"></td><td class="s8"></td><td class="s8" rowspan="2"></td><td class="s8"></td><td class="s8" rowspan="2"></td><td class="s3"></td><td class="s3" rowspan="2"></td></tr><tr style="height: 19px"><th id="380029853R49" style="height: 19px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 19px">50</div></th><td class="s5"><a target="_blank" href="https://arxiv.org/abs/2304.03442">Park, J. S., O&#39;Brien, J. C., Cai, C. J., Morris, M. R., Liang, P., &amp; Bernstein, M. S. (2023). Generative agents: Interactive simulacra of human behavior. arXiv preprint arXiv:2304.03442.</a></td><td class="s17">Adnan Abbas</td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s3"></td></tr><tr style="height: 38px"><th id="380029853R50" style="height: 38px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 38px">51</div></th><td class="s4">29-Nov</td><td class="s33" colspan="2">No Class, Work on Final Project</td><td class="s6"></td><td class="s7"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s3"></td><td class="s3"></td></tr><tr style="height: 38px"><th id="380029853R51" style="height: 38px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 38px">52</div></th><td class="s4">4-Dec</td><td class="s18" colspan="2">Final Presentation</td><td class="s19"></td><td class="s7"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s3"></td><td class="s3"></td></tr><tr style="height: 38px"><th id="380029853R52" style="height: 38px;" class="row-headers-background"><div class="row-header-wrapper" style="line-height: 38px">53</div></th><td class="s4">6-Dec</td><td class="s18" colspan="2">Final Presentation</td><td class="s19"></td><td class="s7"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s3"></td><td class="s3"></td></tr></tbody></table></div>